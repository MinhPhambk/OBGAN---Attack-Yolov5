{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import os\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import shutil\n",
    "# from torchsummary import summary\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import gc\n",
    "# from advertorch.attacks.iterative_projected_gradient import LinfPGDAttack\n",
    "\n",
    "# from confidence-calibrated-adversarial-training\n",
    "def find_last_checkpoint(model_file):\n",
    "    base_directory = os.path.dirname(os.path.realpath(model_file))\n",
    "    file_name = os.path.basename(model_file)\n",
    "\n",
    "    if os.path.exists(base_directory):\n",
    "        state_files = []\n",
    "        files = [os.path.basename(f) for f in os.listdir(base_directory) if os.path.isfile(os.path.join(base_directory, f))]\n",
    "\n",
    "        for file in files:\n",
    "            if file.find(file_name) >= 0 and file != file_name:\n",
    "                state_files.append(file)\n",
    "\n",
    "        if len(state_files) > 0:\n",
    "            epochs = [state_files[i].replace(file_name,'').replace('.', '') for i in range(len(state_files))] \n",
    "            epochs = [epoch for epoch in epochs if epoch.isdigit()]\n",
    "            epochs = list(map(int, epochs))\n",
    "            epochs = [epoch for epoch in epochs if epoch >= 0]\n",
    "\n",
    "            if len(epochs) > 0:\n",
    "                # list is not ordered by epochs!\n",
    "                i = np.argmax(epochs)\n",
    "                return os.path.join(base_directory, file_name + '.%d' % epochs[i])\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "def adv_loss(probs_model, onehot_labels, is_targeted):   \n",
    "    # C&W loss function\n",
    "    real = torch.sum(onehot_labels * probs_model, dim=1)\n",
    "    other, _ = torch.max((1 - onehot_labels) * probs_model - onehot_labels * 10000, dim=1) # loss adv giam thi asr tang 1. index tunning chỉ số càng nhỏ full rate càng tăng\n",
    "    zeros = torch.zeros_like(other)\n",
    "    if is_targeted:\n",
    "        loss_adv = torch.sum(torch.max(other - real, zeros)) \n",
    "    else:\n",
    "        loss_adv = torch.sum(torch.max(real - other, zeros)) \n",
    "    return loss_adv\n",
    "\n",
    "class OBGAN:\n",
    "    def __init__(self,\n",
    "                 device,\n",
    "                 model,\n",
    "                 model_num_labels,\n",
    "                 image_nc,\n",
    "                 epoch_of_change,\n",
    "                 box_min,\n",
    "                 box_max,\n",
    "                 c_tresh,\n",
    "                 class_name,\n",
    "                 batsize,\n",
    "                 dataset_name,\n",
    "                 is_targeted):\n",
    "        \n",
    "        output_nc = image_nc\n",
    "        self.device = device\n",
    "        self.model_num_labels = model_num_labels\n",
    "        self.model = model\n",
    "        self.input_nc = image_nc\n",
    "        self.output_nc = output_nc\n",
    "        self.box_min = box_min\n",
    "        self.box_max = box_max\n",
    "        self.c_treshold = c_tresh \n",
    "        self.class_name = class_name\n",
    "        self.batsize = batsize\n",
    "        self.dataset_name = dataset_name\n",
    "        self.is_targeted = is_targeted\n",
    "        \n",
    "        self.models_path = './models/'\n",
    "        self.writer = SummaryWriter('./checkpoints/logs/', max_queue=100)\n",
    "\n",
    "        self.gen_input_nc = image_nc\n",
    "\n",
    "        self.epoch_of_change = epoch_of_change\n",
    "  \n",
    "        # self.attacker = LinfPGDAttack(self.model, loss_fn=nn.CrossEntropyLoss(reduction=\"sum\"), eps=0.3,\n",
    "        #      nb_iter=40, eps_iter=0.01, rand_init=True, clip_min=box_min, clip_max=box_max,\n",
    "        #      targeted=self.is_targeted)\n",
    "\n",
    "        if dataset_name==\"MS_COCO\":\n",
    "            from Gan_model import Generator \n",
    "            from Gan_model import Discriminator \n",
    "        else:\n",
    "            raise NotImplementedError('dataset [%s] is not implemented' % dataset_name)\n",
    "\n",
    "        self.netG = Generator(self.gen_input_nc, image_nc).to(device)\n",
    "        self.netDisc = Discriminator(image_nc).to(device)\n",
    "        self.netG_file_name = self.models_path + 'netG'\n",
    "        self.netDisc_file_name = self.models_path + 'netD'\n",
    "\n",
    "        os.makedirs(self.models_path, exist_ok=True)\n",
    "\n",
    "        # initialize all weights\n",
    "        last_netG = find_last_checkpoint(self.netG_file_name)\n",
    "        last_netDisc = find_last_checkpoint(self.netDisc_file_name)\n",
    "        if last_netG is not None:\n",
    "            self.netG.load_state_dict(torch.load(last_netG))\n",
    "            self.netDisc.load_state_dict(torch.load(last_netDisc))\n",
    "            *_, self.start_epoch = last_netG.split('.')\n",
    "            self.iteration = None\n",
    "            self.start_epoch = int(self.start_epoch)+1\n",
    "        else:\n",
    "            self.netG.apply(weights_init)\n",
    "            self.netDisc.apply(weights_init)\n",
    "            self.start_epoch = 1\n",
    "            self.iteration = 0\n",
    "\n",
    "       # initialize optimizers\n",
    "        if self.dataset_name == \"MS_COCO\":\n",
    "            lr = 10**(-7) #0.0000001 2. index tunning\n",
    "        else:\n",
    "            raise NotImplementedError('dataset [%s] is not implemented' % dataset_name)\n",
    "\n",
    "        self.optimizer_G = torch.optim.Adam(self.netG.parameters(),\n",
    "                                            lr=lr)\n",
    "        self.optimizer_D = torch.optim.Adam(self.netDisc.parameters(),\n",
    "                                            lr=lr)\n",
    "        #luu cai cai optimizer de lan sau train tiep                                     \n",
    "        self.optG_file_name = self.models_path + 'optG'\n",
    "        self.optD_file_name = self.models_path + 'optD'\n",
    "\n",
    "        last_optG = find_last_checkpoint(self.optG_file_name)\n",
    "        last_optD = find_last_checkpoint(self.optD_file_name)\n",
    "        if last_optG is not None:\n",
    "            self.optimizer_G.load_state_dict(torch.load(last_optG))\n",
    "            self.optimizer_D.load_state_dict((torch.load(last_optD)))\n",
    "\n",
    "        self._use_attacker = (self.start_epoch < self.epoch_of_change)\n",
    "\n",
    "\n",
    "\n",
    "    def train_batch(self, x, labels):    \n",
    "        # optimize D\n",
    "        for _ in range(1):\n",
    "            # # add a clipping trick\n",
    "            perturbation = torch.clamp(self.netG(x), -self.c_treshold, self.c_treshold)\n",
    "            adv_images = 2*perturbation + x \n",
    "            adv_images = torch.clamp(adv_images, self.box_min, self.box_max)\n",
    "\n",
    "            adv_prob = self.model(adv_images).detach().cpu().numpy()\n",
    "            adv_labels = []\n",
    "            # print('G')\n",
    "            # summary(self.netG, (3, 299, 299))\n",
    "            # print('D')\n",
    "            # summary(self.netDisc, (3, 299, 299))\n",
    "            for i in range(len(adv_prob)):\n",
    "                adv_labels.append(np.argmax(adv_prob[i]))\n",
    "\n",
    "            # print('adv_labels ', adv_labels)\n",
    "            label_count = 0\n",
    "            fool_count = 0\n",
    "            for i in range(len(labels)):\n",
    "                label_count += 1\n",
    "                if labels[i] != adv_labels[i]:\n",
    "                    fool_count += 1\n",
    "            fool_rate = fool_count / label_count * 100\n",
    "            print(f\"fool rate: {fool_rate:.2f}%\")\n",
    "            with open(\"./models/fool_rate_log.txt\", 'a', encoding='utf-8') as file:\n",
    "                file.write(str(fool_rate) + '\\n')\n",
    "\n",
    "            target_folder1 =\"./data_temp/adv_temp\"\n",
    "            os.makedirs(target_folder1, exist_ok=True)\n",
    "            for j in range(0,self.batsize):\n",
    "                cv2.imwrite(f\"./data_temp/adv_temp/perturbation_{j}.jpg\", \n",
    "                            cv2.cvtColor(perturbation[j].permute((1,2,0)).detach().cpu().numpy()*255, cv2.COLOR_RGB2BGR))\n",
    "                cv2.imwrite(f\"./data_temp/adv_temp/adv_images_{j}.jpg\", \n",
    "                            cv2.cvtColor(adv_images[j].permute((1,2,0)).detach().cpu().numpy()*255, cv2.COLOR_RGB2BGR))\n",
    "            self.optimizer_D.zero_grad()\n",
    "\n",
    "            #if self._use_attacker:\n",
    "                #pgd_images = self.attacker.perturb(x,labels) \n",
    "                #d_real_logits, d_real_probs = self.netDisc(pgd_images)\n",
    "            #else:\n",
    "            d_real_logits, d_real_probs = self.netDisc(x) \n",
    "            d_fake_logits, d_fake_probs = self.netDisc(adv_images.detach())\n",
    "            # adv_images 1 hoac nhieu tam hinh tuy vao bathsize\n",
    "            # vi du bathsize = 3 thi d_fake_probs cho ra 3 phan tu nhãn sẽ là nhãn 0 >> label goc thi nhan 1\n",
    "            # generate labels for discriminator (optionally smooth labels for stability)\n",
    "         \n",
    "            smooth = 0.1\n",
    "            d_labels_real = torch.ones_like(d_real_probs, device=self.device) * (1 - smooth) # 3 so 1\n",
    "            d_labels_fake = torch.zeros_like(d_fake_probs, device=self.device) # 3 so 0\n",
    "            \n",
    "            # discriminator loss\n",
    "            loss_D_real = F.mse_loss(d_real_probs, d_labels_real)\n",
    "            loss_D_fake = F.mse_loss(d_fake_probs, d_labels_fake)\n",
    "            loss_D_GAN = (6*loss_D_fake + 4*loss_D_real)   #loss D giam thi SSIM va PSNR tang 3. \n",
    "            loss_D_GAN.backward()\n",
    "            self.optimizer_D.step()\n",
    "        #print(\"Final D\")\n",
    "        gc.collect()\n",
    "\n",
    "        # optimize G\n",
    "        for _ in range(1):\n",
    "\n",
    "            self.optimizer_G.zero_grad()\n",
    "\n",
    "            # cal G's loss in GAN\n",
    "            d_fake_logits,d_fake_probs = self.netDisc(adv_images.detach()) \n",
    "            loss_G_fake = F.mse_loss(d_fake_probs, torch.ones_like(d_fake_probs, device=self.device))\n",
    "            loss_G_fake.backward(retain_graph=True)\n",
    "\n",
    "            # # calculate perturbation norm / lam cai loss cang nho cang tot \n",
    "            loss_perturb = torch.norm(perturbation.view(perturbation.shape[0], -1), 2, dim=1)\n",
    "            # co gang thay doi c_treshold sao cho loss_perturb - self.c_treshold <=0 tang\n",
    "            loss_perturb = torch.max(loss_perturb - self.c_treshold, torch.zeros(1, device=self.device))\n",
    "            loss_perturb = torch.mean(loss_perturb)\n",
    "\n",
    "            # Lay ket qua tu model goc ra\n",
    "            f_fake_logits = self.model(adv_images)  \n",
    "      \n",
    "            # Doi ket qua thanh xac suat\n",
    "            f_fake_probs = F.softmax(f_fake_logits, dim=1)\n",
    "\n",
    "            # if training is targeted, indicate how many examples classified as targets\n",
    "            # else show accuraccy on adversarial images\n",
    "\n",
    "            fake_accuracy = torch.mean((torch.argmax(f_fake_probs, 1) == labels).float())\n",
    "\n",
    "            onehot_labels = torch.eye(self.model_num_labels, device=self.device)[labels.long()]\n",
    "            # Tinh loss giua adv va model goc cang cao cang tot\n",
    "            loss_adv = adv_loss(f_fake_probs, onehot_labels, self.is_targeted)\n",
    "            \n",
    "            # feel freeze to change\n",
    "            if self.dataset_name == \"MS_COCO\": #4. index tunning\n",
    "                alambda = 10 #0.5 # 10\n",
    "                alpha = 1 # 1\n",
    "                beta = 0.5 # 0.5 #tăng b foolrate tang, loss G tang  \n",
    "                #print(\"alambda: %.1f,  alpha : %.1f, beta: %.1f, \\n\" %\n",
    "                  #(alambda, alpha, beta ))\n",
    "            else:\n",
    "                raise NotImplementedError('dataset [%s] is not implemented' % self.dataset_name)\n",
    "            # tun 3 gia tri alpha alamda beta, gia tri cang cao the hien quan trong cua loss\n",
    "            loss_G = alambda*loss_adv + alpha*loss_G_fake + beta*loss_perturb\n",
    "            loss_G.backward()\n",
    "            self.optimizer_G.step()\n",
    "        # gia tri sai lech voi anh origin\n",
    "        self.writer.add_scalar('iter/train/loss_D_real', loss_D_real.data, global_step=self.iteration)\n",
    "        # gia tri sai lech voi anh fake\n",
    "        self.writer.add_scalar('iter/train/loss_D_fake', loss_D_fake.data, global_step=self.iteration)\n",
    "        # gia tri sai lech voi anh fake\n",
    "        self.writer.add_scalar('iter/train/loss_G_fake', loss_G_fake.data, global_step=self.iteration)\n",
    "        # noise gauss\n",
    "        self.writer.add_scalar('iter/train/loss_perturb', loss_perturb.data, global_step=self.iteration)\n",
    "        self.writer.add_scalar('iter/train/loss_adv', loss_adv.data, global_step=self.iteration)\n",
    "        self.writer.add_scalar('iter/train/loss_G', loss_G.data, global_step=self.iteration)\n",
    "        self.writer.add_scalar('iter/train/fake_acc', fake_accuracy.data, global_step=self.iteration)\n",
    "        self.iteration += 1\n",
    "        \n",
    "        return loss_D_GAN.item(), loss_G_fake.item(), loss_perturb.item(), loss_adv.item(), loss_G.item(), fake_accuracy\n",
    "\n",
    "    def train(self, train_dataloader, epochs):\n",
    "        if self.iteration is None:\n",
    "            self.iteration = (self.start_epoch-1)*len(train_dataloader)+1\n",
    "       \n",
    "        print(\"Starting training\")\n",
    "        print(epochs)\n",
    "        for epoch in range(self.start_epoch, epochs+1):\n",
    "            with open(\"./models/fool_rate_log.txt\", 'a', encoding='utf-8') as file:\n",
    "                file.write(str(epoch) + '\\n')\n",
    "            print(\"Start epoch num \", epoch)\n",
    "            if epoch == self.epoch_of_change:\n",
    "                self._use_attacker = False                        \n",
    "            loss_D_sum = 0\n",
    "            loss_G_fake_sum = 0\n",
    "            loss_perturb_sum = 0\n",
    "            loss_adv_sum = 0\n",
    "            loss_G_sum = 0\n",
    "            fake_acc_sum = 0\n",
    "            \n",
    "            for i, data in tqdm(enumerate(train_dataloader, start=0)):\n",
    "                gc.collect()\n",
    "                images,labels = data\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)  \n",
    "         \n",
    "                for j in range(0, self.batsize):\n",
    "                    label_index = self.model(images[j], one_img=True)\n",
    "                    if  label_index == None:\n",
    "                        label_index = 80\n",
    "                    labels[j] = label_index              \n",
    "                # print('label', labels)\n",
    "                loss_D_batch, loss_G_fake_batch, loss_perturb_batch, loss_adv_batch, loss_G_batch, fake_acc_batch = \\\n",
    "                      self.train_batch(images, labels)\n",
    "                 \n",
    "                loss_D_sum += loss_D_batch\n",
    "                loss_G_fake_sum += loss_G_fake_batch\n",
    "                loss_perturb_sum += loss_perturb_batch\n",
    "                loss_adv_sum += loss_adv_batch\n",
    "                loss_G_sum += loss_G_batch\n",
    "                fake_acc_sum += fake_acc_batch \n",
    "                     \n",
    "                if i % 50 == 0:\n",
    "                    perturbation = self.netG(images)\n",
    "                    self.writer.add_images('train/adversarial_perturbation', perturbation, global_step=epoch*len(train_dataloader)+i)\n",
    "                    self.writer.add_images('train/adversarial_images', images+perturbation, global_step=epoch*len(train_dataloader)+i)\n",
    "                    self.writer.add_images('train/adversarial_images_cl', torch.clamp(images+perturbation, self.box_min, self.box_max), global_step=epoch*len(train_dataloader)+i)\n",
    "            \n",
    "            # print statistics\n",
    "            num_batch = len(train_dataloader)\n",
    "            self.writer.add_scalar('epoch/train/loss_D', loss_D_sum/num_batch, global_step=epoch)\n",
    "            self.writer.add_scalar('epoch/train/loss_G_fake', loss_G_fake_sum/num_batch, global_step=epoch)\n",
    "            self.writer.add_scalar('epoch/train/loss_perturb', loss_perturb_sum/num_batch, global_step=epoch)\n",
    "            self.writer.add_scalar('epoch/train/loss_adv', loss_adv_sum/num_batch, global_step=epoch)\n",
    "            self.writer.add_scalar('epoch/train/loss_G', loss_G_sum/num_batch, global_step=epoch)\n",
    "            self.writer.add_scalar('epoch/train/fake_acc', fake_acc_sum/num_batch, global_step=epoch)\n",
    "            \n",
    "            print(\"epoch %d:\\nloss_D: %.3f, loss_G_fake: %.3f,\\\n",
    "             \\nloss_perturb: %.3f, loss_adv: %.3f, loss_G: %.3f, \\n\" %\n",
    "                  (epoch, loss_D_sum/num_batch, loss_G_fake_sum/num_batch,\n",
    "                   loss_perturb_sum/num_batch, loss_adv_sum/num_batch, loss_G_sum/num_batch))\n",
    "\n",
    "            # save generator\n",
    "            if epoch%1==0:\n",
    "                netG_file_name = self.netG_file_name + '.'+str(epoch)\n",
    "                torch.save(self.netG.state_dict(), netG_file_name)\n",
    "                netD_file_name = self.netDisc_file_name  + '.'+ str(epoch) \n",
    "                torch.save(self.netDisc.state_dict(), netD_file_name)\n",
    "                optG_file_name = self.optG_file_name  + '.' + str(epoch) \n",
    "                torch.save(self.optimizer_G.state_dict(), optG_file_name)\n",
    "                optD_file_name = self.optD_file_name  + '.' + str(epoch) \n",
    "                torch.save(self.optimizer_D.state_dict(), optD_file_name)\n",
    "            \n",
    "        #save final model\n",
    "        torch.save(self.netG.state_dict(), self.netG_file_name )\n",
    "        torch.save(self.netDisc.state_dict(), self.netDisc_file_name)\n",
    "        torch.save(self.optimizer_G.state_dict(), self.optG_file_name)\n",
    "        torch.save(self.optimizer_D.state_dict(), self.optD_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n",
      "Using device:  cuda\n",
      "Successfully loaded target model  YOLOv5\n",
      "training image examples:  5577\n",
      "Starting training\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from yolov5_infer import model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    use_cuda=True\n",
    "    image_nc=3\n",
    "    epochs = 600\n",
    "    batch_size = 128\n",
    "    C_TRESH =  1  #c cang thap thi nhieu cang min\n",
    "    BOX_MIN = 0\n",
    "    BOX_MAX = 1\n",
    "    # increase to speed up training phase but be carefull of how model is gonna be converged\n",
    "    # Define what device we are using\n",
    "    device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "    print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "    print(\"Using device: \", device)\n",
    "\n",
    "    #Gene: input tam hinh goc  >> pert : encoder sau conv2d lam nho cai hinh down scaling >> up sampling  decode lam to cai hinh lai >> hinh goc\n",
    "    #Dicri: input  Output G (pert) >> d_fake_probs output xac xuat D , D_fake : 1 tam hinh nha ra 1 phantu ( kiem tra pert co thay doi dc label ko)\n",
    "\n",
    "    #MODEL_Taget\n",
    "    MODEL_NAME = \"YOLOv5\"\n",
    "\n",
    "    print(\"Successfully loaded target model \", MODEL_NAME)\n",
    "\n",
    "    model_num_labels = 80\n",
    "    CLASS_NAMES = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "            'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "            'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "            'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "            'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "            'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "            'hair drier', 'toothbrush']\n",
    "    \n",
    "    model_num_labels = 80\n",
    "\n",
    "    stop_epoch = 5    \n",
    "            \n",
    "    #coco_dataset = torchvision.datasets.ImageFolder('./dataset/train_1_class', transform=transforms.ToTensor())\n",
    "    coco_dataset = torchvision.datasets.ImageFolder('./dataset/train_dog_cat_person', transform=transforms.ToTensor())\n",
    "    dataloader = DataLoader(coco_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    print(\"training image examples: \", coco_dataset.__len__())\n",
    "\n",
    "    obGAN = OBGAN(device,\n",
    "                model,\n",
    "                model_num_labels,\n",
    "                image_nc,\n",
    "                stop_epoch,\n",
    "                BOX_MIN,\n",
    "                BOX_MAX,\n",
    "                C_TRESH,\n",
    "                class_name = CLASS_NAMES,\n",
    "                batsize = batch_size,\n",
    "                dataset_name=\"MS_COCO\",\n",
    "                is_targeted=False)\n",
    "\n",
    "    obGAN.train(dataloader, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yolov7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
